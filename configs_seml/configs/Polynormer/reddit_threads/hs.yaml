seml:
  executable: main.py
  output_dir: configs_seml/logs
  project_root_dir: ../../../..
  conda_environment: gtr

slurm:
  experiments_per_job: 2
  sbatch_options:
    partition: <slurm-gpu-partition>
    gres: gpu:1
    mem: 16G
    cpus-per-task: 2
    time: 1-00:00
    

# Hyperparameter search

random:
  samples: 30
  seed: 373

  graphgym.seed:
    seed: 1828
    type: randint
    min: 0
    max: 10000

  graphgym.optim.base_lr:
    seed: 2264
    type: loguniform
    min: 8.0e-5
    max: 5.0e-2

  dims_per_head:
    seed: 514
    type: randint
    min: 6
    max: 25

  graphgym.gnn.layers_mp:
    seed: 672
    type: randint
    min: 2
    max: 6

  graphgym.gt.layers:
    seed: 7625
    type: randint
    min: 2
    max: 8

  graphgym.gt.dropout:
    seed: 8625
    type: uniform
    min: 0.2
    max: 0.4

# experiment fixed configs

fixed:

  graphgym:

    accelerator: cuda
    out_dir: configs_seml/results
    metric_best: accuracy
    metric_agg: argmax
    tensorboard_each_run: false

    dataset:
      format: PyG-TUDataset
      name: reddit_threads
      task: graph
      task_type: classification_binary
      transductive: false
      split_mode: cv-stratifiedkfold-8
      split_index: 6
      split_dir: datasets/splits
      node_encoder: true
      node_encoder_name: LinearNode
      node_encoder_bn: false
      edge_encoder: false

    train:
      mode: custom
      eval_period: 1
      enable_ckpt: true
      batch_size: 64  # very small graphs

    model:
      type: WeightedPolynormer
      loss_fun: cross_entropy

    gt:
      dim_hidden: 0  # determined using num_heads and dims_per_head
      n_heads: 3
      polynormer:
        dropout_node_input: 0.0
        local_pre_layer_norm: false
        beta: -1.0
        qk_shared: false

    gnn:
      head: weighted_mean_pool_graph
      layers_pre_mp: 0
      dim_inner: 0  # determined using num_heads and dims_per_head
      att_heads: 3
      dropout: 0.0
      layers_post_mp: 1

    optim:
      clip_grad_norm: true
      clip_grad_norm_value: 5.0
      optimizer: adamW
      weight_decay: 0.0
      max_epoch: 30
      scheduler: cosine_with_warmup
      early_stopping: true
      early_stopping_patience: 7
      early_stopping_delta_e: 0.01
      early_stopping_warmup: 3
      num_warmup_epochs: 1
      num_local_epochs: 0

    attack:
      enable: false
