seml:
  executable: main.py
  output_dir: configs_seml/logs
  project_root_dir: ../../../..
  conda_environment: gtr

slurm:
  experiments_per_job: 11
  sbatch_options:
    partition: <slurm-gpu-partition>
    gres: gpu:1
    mem: 42G
    cpus-per-task: 4
    time: 1-00:00
    

# experiment random configs
  
random:
  samples: 30
  seed: 31313

  graphgym.seed:
    seed: 1425
    type: randint
    min: 0
    max: 10000

  graphgym.optim.base_lr:
    seed: 264
    type: loguniform
    min: 1e-5
    max: 5e-2

  graphgym.optim.weight_decay:
    seed: 809
    type: loguniform
    min: 5e-7
    max: 1e-1

  dims_per_head:
    seed: 1094
    type: randint
    min: 4
    max: 14

  graphgym.gt.layers:
    seed: 3357
    type: randint
    min: 2
    max: 13

  graphgym.gt.dropout:
    seed: 61
    type: uniform
    min: 0.0
    max: 0.1

  graphgym.gt.gamma:
    seed: 982
    type: loguniform
    min: 3.0e-4
    max: 3.0

  graphgym.posenc_WLapPE.layers:
    seed: 51
    type: choice
    options:
      - 1
      - 2

  dims_per_head_PE:
    seed: 6384
    type: randint
    min: 1
    max: 4

  graphgym.posenc_WLapPE.eigen.max_freqs:
    seed: 52157
    type: randint
    min: 5
    max: 20
  
  graphgym.gnn.layers_post_mp:
    seed: 966
    type: choice
    options:
      - 1
      - 3

# experiment fixed configs 

fixed:

  graphgym:

    accelerator: cuda
    out_dir: configs_seml/results
    metric_best: accuracy
    metric_agg: argmax
    tensorboard_each_run: false

    dataset:
      format: PyG-TUDataset
      name: ENZYMES
      task: graph
      task_type: classification
      transductive: false
      split_mode: cv-stratifiedkfold-10
      split_index: 0
      node_encoder: true
      node_encoder_name: WLapPE
      node_encoder_bn: false
      edge_encoder: true
      edge_encoder_bn: false
      edge_encoder_name: WeightedSANDummyEdge

    train:
      mode: custom
      batch_size: 32
      eval_period: 1

    posenc_WLapPE:
      enable: true
      eigen:
        laplacian_norm: sym
        eigvec_norm: L2
      model: Transformer
      n_heads: 8
      dim_pe: 0  # determined by heads and dim per head
      raw_norm_type: none
      post_layers: 0
      pass_as_var: false
      w_add_dummy_edge: false

    model:
      type: WeightedSANTransformer
      loss_fun: cross_entropy

    gt:
      n_heads: 8
      dim_hidden: 0  # determined using num_heads and dims_per_head
      full_graph: true
      gamma_learnable: false
      layer_norm: false
      batch_norm: true
      residual: true
      attn:
        use_bias: false
        clamp: 5.0

    gnn:
      head: weighted_add_pool_graph
      layers_pre_mp: 0
      dim_inner: 0  # determined using num_heads and dims_per_head

    optim:
      optimizer: adamW
      max_epoch: 500
      scheduler: reduce_on_plateau
      reduce_factor: 0.5
      schedule_patience: 7
      min_lr: 1.0e-5
      early_stopping: true
      early_stopping_patience: 50
      early_stopping_delta_e: 0.02
      early_stopping_warmup: 50
      clip_grad_norm: true
      clip_grad_norm_value: 5.0
      
    attack:
      enable: false
