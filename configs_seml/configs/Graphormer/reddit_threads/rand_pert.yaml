seml:
  executable: main.py
  output_dir: configs_seml/logs
  project_root_dir: ../../../..
  conda_environment: gtr

slurm:
  experiments_per_job: 2
  sbatch_options:
    partition: <slurm-gpu-partition>
    gres: gpu:1
    mem: 24G
    cpus-per-task: 2
    time: 1-00:00
    

grid:

  graphgym.seed:
    type: choice
    options:
      - 42
      - 670
      - 7813
      - 9537

  graphgym.attack.e_budget:
    type: choice
    options:
      - 0.05
      - 0.1
      - 0.2
      - 0.4
      - 0.8

# experiment fixed configs

fixed:

  graphgym:

    out_dir: configs_seml/results

    pretrained:
      dir: '/<your-saved-path>/models/Graphormer/reddit_threads/0'
      finetune: false

    attack:
      enable: true
      only_random_baseline: true
      epochs: 0
      max_final_samples: 1
      num_attacked_graphs: 50
      skip_incorrect_graph_classification: false
      log_progress: false
      load_best_model: false
      split: test
      prediction_level: graph
      remove_isolated_components: false
      block_size: 6000
      epochs_resampling: 100
      resample_period: 1
      eps: 1.0e-07
      eps_init_noised: false
      is_undirected: true
      loss: raw_prediction
      metric: neg_accuracy
      lr: 4000
      max_edge_weight_update: 0.0
      max_trials_sampling: 20
      minimum_budget: 1
      node_prob_enable: false
      root_node_idx: null
      with_early_stopping: true
      cluster_sampling: false
      node_injection:
        enable: false
  
    # copied from pre-trained model
    accelerator: cuda
    bn:
      eps: 1.0e-05
      mom: 0.1
    dataset:
      cache_load: false
      cache_save: false
      dir: ./datasets
      edge_dim: 128
      edge_encoder: false
      edge_encoder_bn: true
      edge_encoder_name: Bond
      edge_encoder_num_types: 0
      edge_message_ratio: 0.8
      edge_negative_sampling_ratio: 1.0
      edge_train_mode: all
      encoder: true
      encoder_bn: true
      encoder_dim: 128
      encoder_name: db
      format: PyG-TUDataset
      infer_link_label: None
      label_column: none
      label_table: none
      location: local
      name: reddit_threads
      node_encoder: true
      node_encoder_bn: false
      node_encoder_name: LinearNode+WeightedGraphormerBias
      node_encoder_num_types: 0
      pe_transform_on_the_fly: false
      remove_feature: false
      resample_disjoint: false
      resample_negative: false
      shuffle_split: true
      slic_compactness: 10
      split:
      - 0.8
      - 0.1
      - 0.1
      split_dir: datasets/splits
      split_index: 6
      split_mode: cv-stratifiedkfold-8
      task: graph
      task_type: classification_binary
      to_undirected: false
      transductive: false
      transform: none
      tu_simple: true
    gnn:
      act: relu
      agg: add
      att_final_linear: false
      att_final_linear_bn: false
      att_heads: 1
      batchnorm: true
      clear_feature: true
      dim_inner: 48
      dropout: 0.0
      head: graphormer_graph
      keep_edge: 0.5
      l2norm: true
      layer_type: generalconv
      layers_mp: 2
      layers_post_mp: 1
      layers_pre_mp: 0
      msg_direction: single
      normalize_adj: false
      residual: false
      self_msg: concat
      skip_every: 1
      stage_type: stack
    graphormer:
      attention_dropout: 0.13840139401179627
      dropout: 0.0496090552330304
      embed_dim: 48
      input_dropout: 0.0
      mlp_dropout: 0.012110979158591462
      num_heads: 8
      num_layers: 6
      use_graph_token: true
    metric_agg: argmax
    metric_best: accuracy
    model:
      edge_decoding: dot
      graph_pooling: graph_token
      loss_fun: cross_entropy
      match_upper: true
      size_average: mean
      thresh: 0.5
      type: Graphormer
    posenc_GraphormerBias:
      dim_pe: 0
      directed_graphs: false
      enable: true
      has_edge_attr: false
      node_degrees_only: false
      num_in_degrees: 42
      num_out_degrees: 42
      num_spatial_types: 8
    optim:
      base_lr: 0.00010487262360040141
      batch_accumulation: 1
      clip_grad_norm: true
      clip_grad_norm_value: 5.0
      early_stopping: true
      early_stopping_delta_e: 0.05
      early_stopping_patience: 7
      early_stopping_warmup: 3
      lr_decay: 0.1
      max_epoch: 30
      min_lr: 0.0
      momentum: 0.9
      num_local_epochs: 0
      num_warmup_epochs: 1
      optimizer: adamW
      reduce_factor: 0.1
      schedule_patience: 10
      scheduler: cosine_with_warmup
      steps:
      - 30
      - 60
      - 90
      weight_decay: 1.1795089293542234e-06
