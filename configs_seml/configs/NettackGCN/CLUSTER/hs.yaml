seml:
  executable: main.py
  output_dir: configs_seml/logs
  project_root_dir: ../../../..
  conda_environment: gtr

slurm:
  experiments_per_job: 6
  sbatch_options:
    partition: <slurm-gpu-partition>
    gres: gpu:1
    mem: 24G
    cpus-per-task: 2
    time: 1-00:00
    

random:
  samples: 60
  seed: 187

  graphgym.seed:
    seed: 786
    type: randint
    min: 0
    max: 10000

  graphgym.optim.base_lr:
    seed: 2264
    type: loguniform
    min: 1e-4
    max: 1e-3

  graphgym.optim.weight_decay:
    seed: 89
    type: loguniform
    min: 1e-4
    max: 1e-1

  graphgym.gnn.dim_inner:
    seed: 4275
    type: randint
    min: 80
    max: 400

# experiment fixed configs - from benchmarking paper

fixed:

  graphgym:

    accelerator: cuda
    out_dir: configs_seml/results
    metric_best: accuracy-SBM
    metric_agg: argmax
    tensorboard_each_run: false

    dataset:
      format: PyG-GNNBenchmarkDataset
      name: CLUSTER
      task: graph
      task_type: classification
      transductive: false
      split_mode: standard
      node_encoder: true
      node_encoder_name: LinearNode
      node_encoder_bn: false
      edge_encoder: false

    train:
      mode: custom
      batch_size: 64
      eval_period: 1

    model:
      type: NettackGCN
      loss_fun: weighted_cross_entropy

    gnn:
      layer_type: gcnconvweighted
      head: inductive_node
      act: identity
      layers_pre_mp: 0
      layers_mp: 2
      layers_post_mp: 0
      batchnorm: false
      dropout: 0.01

    optim:
      optimizer: adamW
      max_epoch: 150
      scheduler: reduce_on_plateau
      reduce_factor: 0.5
      schedule_patience: 5
      min_lr: 1.0e-5
      clip_grad_norm: false
      early_stopping: true
      early_stopping_patience: 25
      early_stopping_delta_e: 0.01
      early_stopping_warmup: 25

    attack:
      enable: false
